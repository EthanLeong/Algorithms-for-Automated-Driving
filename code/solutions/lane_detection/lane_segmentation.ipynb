{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lane Boundary Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delete this \"Setting up Colab\" section if you work locally and do not want to use Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_nb = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_nb:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_nb:\n",
    "  %cd drive/My\\ Drive/aad/code/solutions/lane_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab_nb:\n",
    "  !pip install segmentation-models-pytorch\n",
    "  !pip install albumentations --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import sys\n",
    "sys.path.append(\"../../util\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have collected data yourself in a folder \"data\" using `collect_data.py` and you want to use it for training, set the boolean in the next cell to `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if own_data:\n",
    "    from seg_data_util import sort_collected_data\n",
    "    # copy and sort content of 'data' into 'data_lane_segmentation' folder:\n",
    "    sort_collected_data()\n",
    "    # Since data was copied, you can remove files in 'data' directory afterwards\n",
    "else:\n",
    "    # if you stopped the download before completion, please delete the 'data_lane_segmentation' folder and run this cell again\n",
    "    from seg_data_util import download_segmentation_data\n",
    "    download_segmentation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent of what you chose, you will have a directory 'data_lane_segmentation' now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data_lane_segmentation\"\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'train_label')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'val_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"Plot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarlaLanesDataset(Dataset):\n",
    "    \"\"\" Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = ['background', 'left_marker', 'right_marker']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        #random.shuffle(self.ids)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        get_label_name = lambda fn: re.sub(\".png\", \"_label.png\", fn)\n",
    "        self.masks_fps = [os.path.join(masks_dir, get_label_name(image_id)) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, LongTensor(mask)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CarlaLanesDataset(x_train_dir, y_train_dir, classes=CarlaLanesDataset.CLASSES)\n",
    "\n",
    "image, mask = dataset[4] # get some sample\n",
    "visualize(\n",
    "    image=image, \n",
    "    label = mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is a powerful technique to increase the amount of your data and prevent model overfitting.  \n",
    "\n",
    "Note that we do **not** apply horizontal flip, since this would also flip our labels (right boundary would be labeled left boundary).\n",
    "\n",
    "All this transforms can be easily applied with [**Albumentations**](https://github.com/albu/albumentations/) - fast augmentation library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        albu.ShiftScaleRotate(scale_limit=0.1, rotate_limit=0., shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        albu.IAAAdditiveGaussianNoise(p=0.2),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.CLAHE(p=1),\n",
    "                albu.RandomBrightness(p=1),\n",
    "                albu.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.6,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.IAASharpen(p=1),\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.6,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomContrast(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.6,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    return None\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):   \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Visualize resulted augmented images and masks\n",
    "\n",
    "augmented_dataset = CarlaLanesDataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(), \n",
    "    classes=CarlaLanesDataset.CLASSES,\n",
    ")\n",
    "\n",
    "# same image with different random transforms\n",
    "for i in range(3):\n",
    "    image, mask = augmented_dataset[1]\n",
    "    visualize(image=image, label=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_string = 'multi_dice_loss'\n",
    "\n",
    "ENCODER = 'efficientnet-b0'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'softmax2d'\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.FPN(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CarlaLanesDataset.CLASSES), \n",
    "    activation=ACTIVATION,\n",
    "    #encoder_depth = 4\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CarlaLanesDataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CarlaLanesDataset.CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = CarlaLanesDataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CarlaLanesDataset.CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_train = 8 if colab_nb else 2\n",
    "bs_valid = 8 if colab_nb else 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs_train, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=bs_valid, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.utils import base\n",
    "from segmentation_models_pytorch.utils.losses import DiceLoss\n",
    "from segmentation_models_pytorch.utils.metrics import Accuracy\n",
    "\n",
    "label_left = CarlaLanesDataset.CLASSES.index('left_marker')\n",
    "label_right = CarlaLanesDataset.CLASSES.index('right_marker')\n",
    "\n",
    "class MultiDiceLoss(base.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.BinaryDiceLossLeft = DiceLoss()\n",
    "        self.BinaryDiceLossRight = DiceLoss()\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        #print(\"shape y_pr:\", y_pr.shape)\n",
    "        #print(\"shape y_gt:\", y_gt.shape)\n",
    "        # ypr.shape=bs,3,512,1024, ygt.shape=bs,512,1024\n",
    "        left_gt = (y_gt == label_left)\n",
    "        right_gt = (y_gt == label_right)\n",
    "        loss_left = self.BinaryDiceLossLeft.forward(y_pr[:,label_left,:,:] , left_gt)\n",
    "        loss_right = self.BinaryDiceLossRight.forward(y_pr[:,label_right,:,:] , right_gt)\n",
    "        return (loss_left + loss_right)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "loss = MultiDiceLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=1e-4),\n",
    "    #dict(params=model.parameters(), lr=1e-3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners \n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "best_loss = 1e10\n",
    "\n",
    "for i in range(0, 5):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if best_loss > valid_logs[loss_string]:\n",
    "        best_loss = valid_logs[loss_string]\n",
    "        torch.save(model, './best_model_{}.pth'.format(loss_string))\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 3:\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5\n",
    "        print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "best_model = torch.load('./best_model_multi_dice_loss.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_model = False\n",
    "if test_best_model:\n",
    "    # create test dataset\n",
    "    test_dataset = CarlaLanesDataset(\n",
    "        x_valid_dir, \n",
    "        y_valid_dir, \n",
    "        augmentation=get_validation_augmentation(), \n",
    "        preprocessing=get_preprocessing(preprocessing_fn),\n",
    "        classes=CarlaLanesDataset.CLASSES,\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "    # evaluate model on test set\n",
    "    test_epoch = smp.utils.train.ValidEpoch(\n",
    "        model=best_model,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    logs = test_epoch.run(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset without transformations for image visualization\n",
    "test_dataset_vis = CarlaLanesDataset(\n",
    "    x_valid_dir, y_valid_dir, \n",
    "    classes=CarlaLanesDataset.CLASSES,\n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    n = np.random.choice(len(test_dataset_vis))\n",
    "    \n",
    "    image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "    image, gt_mask = test_dataset_vis[n]\n",
    "    \n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask_left = best_model.predict(x_tensor)[0,1,:,:] \n",
    "    pr_mask_left = (pr_mask_left.cpu().numpy())\n",
    "\n",
    "    pr_mask_right = best_model.predict(x_tensor)[0,2,:,:] \n",
    "    pr_mask_right = (pr_mask_right.cpu().numpy())\n",
    "        \n",
    "    visualize( \n",
    "        ground_truth_mask=gt_mask, \n",
    "        predicted_mask_left=pr_mask_left,\n",
    "        predicted_mask_right=pr_mask_right\n",
    "    )"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
